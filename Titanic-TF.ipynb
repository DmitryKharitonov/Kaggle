{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "import tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source and Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_set = np.load(\"./Titanic-misc/train.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_unshuffled = inputs_set[\"inputs\"]\n",
    "targets_unshuffled = inputs_set[\"outputs\"]\n",
    "\n",
    "\n",
    "inputs_shuffled, targets_shuffled = shuffle(inputs_unshuffled, targets_unshuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = np.int64(targets_shuffled.size * 0.8)\n",
    "\n",
    "train_inputs = inputs_shuffled[0:train_size,:]\n",
    "train_targets = targets_shuffled[0:train_size]\n",
    "\n",
    "validation_inputs = inputs_shuffled[train_size:,:]\n",
    "validation_targets = targets_shuffled[train_size:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HP HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_input_size = inputs_shuffled[0].size\n",
    "HP_hidden_size = 14\n",
    "HP_output_size = 2\n",
    "\n",
    "HP_epochs = 100\n",
    "BATCH_PER_EPOCH = 10 # batch per 1 Epoch\n",
    "\n",
    "HP_optimizer = tf.keras.optimizers.Adam() # learning rate adaptive schedule + momentum\n",
    "HP_loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "# TensorBoard\n",
    "log_dir = \"./Titanic-misc/logs\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Early Stopping\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Flatter layer skipped because all preprocessing was done earlier\n",
    "    tf.keras.layers.Dense(HP_hidden_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(HP_hidden_size,activation='relu'),\n",
    "    tf.keras.layers.Dense(HP_output_size,activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=HP_optimizer, loss=HP_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_inputs, train_targets,\n",
    "          epochs=HP_epochs,\n",
    "          batch_size=BATCH_PER_EPOCH,\n",
    "          validation_data=[validation_inputs,validation_targets],\n",
    "          callbacks=[tensorboard_callback,earlyStopping],\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"./Titanic-misc\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.load(\"./Titanic-misc/test.npz\")\n",
    "test_inputs = test_set[\"inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict_on_batch(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"./Titanic-misc/test.csv\")\n",
    "results = pd.concat([results,pd.DataFrame(test_predict, columns=[\"Not Survived\",\"Survived\"])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survival(x):\n",
    "    if x<0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "\n",
    "export = results[[\"PassengerId\",\"Survived\"]]\n",
    "export[\"Survived\"]=export[\"Survived\"].apply(survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.to_csv(\"./Titanic-misc/result_TF_\"+np.str(pd.Timestamp.now())+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
